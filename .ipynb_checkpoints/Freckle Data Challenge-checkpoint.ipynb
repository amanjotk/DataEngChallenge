{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the dataset\n",
    "\n",
    "An intial look at the raw unzipped data shows the files are in JSON format. Since JSON is a schema-based format and DataFrames are optimized to work efficiently with a data with a schema, I have used dataframes to analyze this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.2.0\n",
      "      /_/\n",
      "\n",
      "Using Python version 2.7.9 (default, Dec 15 2014 10:37:34)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "# initialize spark shell\n",
    "import os\n",
    "execfile(os.path.join(os.environ[\"SPARK_HOME\"], 'python/pyspark/shell.py'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- action: string (nullable = true)\n",
      " |-- api_key: string (nullable = true)\n",
      " |-- app_id: string (nullable = true)\n",
      " |-- beacon_major: long (nullable = true)\n",
      " |-- beacon_minor: long (nullable = true)\n",
      " |-- beacon_uuid: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- code: string (nullable = true)\n",
      " |-- community: string (nullable = true)\n",
      " |-- community_code: string (nullable = true)\n",
      " |-- country_code: string (nullable = true)\n",
      " |-- county: string (nullable = true)\n",
      " |-- county_code: string (nullable = true)\n",
      " |-- event_time: long (nullable = true)\n",
      " |-- geohash: string (nullable = true)\n",
      " |-- horizontal_accuracy: double (nullable = true)\n",
      " |-- idfa: string (nullable = true)\n",
      " |-- idfa_hash_alg: string (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- lng: double (nullable = true)\n",
      " |-- place: string (nullable = true)\n",
      " |-- platform: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- user_ip: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read in the data and print the schema\n",
    "\n",
    "df = spark.read.json('/Users/akaur/Desktop/DataEngChallenge/location-data-sample')\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics for location events per IDFA\n",
    "\n",
    "For the max, min, avg, std deviation of the number of location events per IDFA, first we get the count of the records per IDFA and store it in a new dataframe, then we get the values for the required metrics using the very handy 'describe' function from the spark inbuilt sql functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                idfa|count|\n",
      "+--------------------+-----+\n",
      "|b5b237fe-4ab2-4f0...|   28|\n",
      "|0894896b-1b58-4b8...|   58|\n",
      "|0446d012-6d80-4b2...|   36|\n",
      "|564fa141-580a-445...|   72|\n",
      "|4bf5568f-4369-421...|   31|\n",
      "|b2a03e10-3b45-479...|   94|\n",
      "|f4503b93-f2ec-418...|   48|\n",
      "|fe64cf85-bd56-4d1...|  245|\n",
      "|71f57c4d-78fa-448...|   33|\n",
      "|ef2d34f9-07fd-4cf...|   89|\n",
      "+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# number of locations events(records) per IDFA\n",
    "idfa_count = df.groupBy(df.idfa).count()\n",
    "idfa_count.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|             count|\n",
      "+-------+------------------+\n",
      "|  count|            238211|\n",
      "|   mean| 36.79234376246269|\n",
      "| stddev|118.69280626757613|\n",
      "|    min|                 1|\n",
      "|    max|             15999|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get the aggregation metrics for the count column\n",
    "idfa_count.describe('count').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geohashes of all coordinates\n",
    "In order to get the geohashes for all coordinates, we select distinct tuples of lat, long and geohash by first selecting the three columns and then doing a distinct over the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+------------+\n",
      "|       lat|         lng|     geohash|\n",
      "+----------+------------+------------+\n",
      "|43.8799046| -79.7387178|dpz39s04cpnd|\n",
      "|43.0179897| -81.2123496|dpwhxznvzne0|\n",
      "| 45.268008|  -75.306878|f243w2g1q83c|\n",
      "|39.8381067|  -85.996203|dp4feh73z1r7|\n",
      "| 45.429277|  -73.312884|f25f7wphtzp9|\n",
      "|33.6508982| -86.2153236|djfxqjgytq56|\n",
      "|33.4084427|-111.9747922|9tbq5cy6q1p7|\n",
      "|32.9452214| -87.1452896|djf52vqxzd6k|\n",
      "|38.0779899| -78.4741732|dqb0w7bu75z3|\n",
      "|42.3185033| -89.0907915|dp88sxy54hfc|\n",
      "|32.6601029| -96.5708318|9vg3f3x6bs2w|\n",
      "| 33.577859|  -79.029531|djzz18smnqwd|\n",
      "|31.2965654| -85.7604213|dje403r5tqeh|\n",
      "|41.8792052| -94.0947443|9zmn4zfk199m|\n",
      "|32.4636283|  -99.708028|9vc0ejff6dct|\n",
      "|37.7026782|-122.4443142|9q8ymxwf08tg|\n",
      "|45.1598639| -93.8706887|cbj0zvj7q2v3|\n",
      "|45.3641305| -75.7888115|f24456k30wy5|\n",
      "| 27.067164|  -82.419769|dhv3urrv8jjf|\n",
      "| 30.391329| -88.6527619|dj2uyst42fme|\n",
      "+----------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "geohash_df = df.select(df.lat, df.lng, df.geohash).distinct()\n",
    "geohash_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the dataframe locally for later lookup if required\n",
    "geohash_df.write.parquet('/Users/akaur/PycharmProjects/DataEngChallenge-Amanjot/geohash_coordinates.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geohash - based clusters\n",
    "\n",
    "Using the information that locations/coordinates with similar geohash prefixes are close, I look at different length of geohash prefixes to see the volume of distinct IDFAs in the proximity and whether they can be classified as clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----+\n",
      "|     geohash| vol|\n",
      "+------------+----+\n",
      "|s00000000000|4427|\n",
      "|djfq0rzn7m70|  75|\n",
      "|dq21mmek4q6q|  73|\n",
      "|9vkh7wddguw5|  63|\n",
      "|dpz8336uu2eq|  61|\n",
      "|f244mdxpncbp|  58|\n",
      "|dpm5wpyg42f9|  52|\n",
      "|djfmbs7xs1j8|  48|\n",
      "|f241b833vv6j|  47|\n",
      "|djgzq3q23u2p|  46|\n",
      "|djkvw9r4j8vp|  45|\n",
      "|djt54wb39fhy|  44|\n",
      "|dn6m9tgey6mq|  44|\n",
      "|djdxvzvm9wvu|  43|\n",
      "|dnkkg7cw8k1b|  39|\n",
      "|dnq1zws4u9te|  38|\n",
      "|dpscv16bk3zf|  38|\n",
      "|dpherfur8ezf|  38|\n",
      "|f2418x4h86s2|  37|\n",
      "|c2b2mbftz52c|  37|\n",
      "+------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as func\n",
    "df.groupBy(df.geohash)\\\n",
    "    .agg(func.countDistinct(df.idfa).alias('vol'))\\\n",
    "    .sort('vol', ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that geohash 's00000000000' has a very high volume of IDFAs compared to any other geohash, this seems like an outlier caused by possibly artificial traffic or some other inaccuracy in the data. Let's check the cities/coordinates for this geohash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|     city|\n",
      "+---------+\n",
      "|Barrigada|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.city)\\\n",
    "    .filter(df.geohash == 's00000000000')\\\n",
    "    .distinct()\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the city Barrigada responsible for this unusually high amount of traffic is a small village with a population of  < 9K, it is safe to assume this is some kind of artificial/fraud/bot traffic. Going forward, we filter out this geohash in our analysis in order to avoid any skew in data because of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+-----+\n",
      "|substring(geohash, 1, 4)|count|\n",
      "+------------------------+-----+\n",
      "|                    dpz8| 4315|\n",
      "|                    dpz2| 3676|\n",
      "|                    dpz9| 2535|\n",
      "|                    f25d| 1938|\n",
      "|                    c3nf| 1825|\n",
      "|                    dpxr| 1792|\n",
      "|                    f244| 1749|\n",
      "|                    9vk1| 1743|\n",
      "|                    9vg5| 1689|\n",
      "|                    9vk0| 1636|\n",
      "|                    dr4e| 1612|\n",
      "|                    dn5b| 1595|\n",
      "|                    c3x2| 1581|\n",
      "|                    dpsc| 1574|\n",
      "|                    dqcx| 1569|\n",
      "|                    9vg4| 1569|\n",
      "|                    dphg| 1558|\n",
      "|                    dqcr| 1535|\n",
      "|                    djgz| 1514|\n",
      "|                    dnh0| 1510|\n",
      "|                    9vk4| 1415|\n",
      "|                    f25e| 1414|\n",
      "|                    9vff| 1399|\n",
      "|                    dpsb| 1384|\n",
      "|                    c2b2| 1384|\n",
      "|                    dpj5| 1356|\n",
      "|                    djup| 1347|\n",
      "|                    dpz3| 1321|\n",
      "|                    dr5r| 1262|\n",
      "|                    c2b8| 1262|\n",
      "|                    f241| 1246|\n",
      "|                    c28x| 1141|\n",
      "|                    dn6m| 1116|\n",
      "|                    dpzc| 1086|\n",
      "|                    dngy| 1059|\n",
      "|                    cbfg| 1053|\n",
      "|                    9z7d| 1051|\n",
      "|                    dq25|  991|\n",
      "|                    dnh1|  982|\n",
      "|                    9yzg|  981|\n",
      "|                    dpxn|  980|\n",
      "|                    dp3w|  972|\n",
      "|                    9vfc|  971|\n",
      "|                    dpmg|  971|\n",
      "|                    dr72|  962|\n",
      "|                    9yzu|  944|\n",
      "|                    dngz|  936|\n",
      "|                    9vgh|  934|\n",
      "|                    9vg1|  925|\n",
      "|                    dqcj|  924|\n",
      "|                    dnkk|  918|\n",
      "|                    djfq|  898|\n",
      "|                    dnn3|  893|\n",
      "|                    dqcm|  884|\n",
      "|                    9qqj|  880|\n",
      "|                    dn5c|  867|\n",
      "|                    c3x0|  856|\n",
      "|                    9q5c|  855|\n",
      "|                    9vfg|  846|\n",
      "|                    dp4d|  840|\n",
      "|                    dq8v|  838|\n",
      "|                    djun|  837|\n",
      "|                    dp3t|  837|\n",
      "|                    dnkh|  833|\n",
      "|                    dp4f|  823|\n",
      "|                    c3nc|  822|\n",
      "|                    9qh0|  798|\n",
      "|                    9y69|  795|\n",
      "|                    dnq8|  794|\n",
      "|                    dnru|  786|\n",
      "|                    dq9c|  783|\n",
      "|                    dpwz|  779|\n",
      "|                    dn5r|  773|\n",
      "|                    dpwh|  766|\n",
      "|                    9zvx|  766|\n",
      "|                    dphu|  762|\n",
      "|                    dqcq|  759|\n",
      "|                    dj3q|  750|\n",
      "|                    dpxq|  728|\n",
      "|                    dqch|  717|\n",
      "|                    c28r|  705|\n",
      "|                    dpqh|  699|\n",
      "|                    9vrf|  697|\n",
      "|                    9tbq|  696|\n",
      "|                    djn4|  686|\n",
      "|                    dpxj|  680|\n",
      "|                    9vk2|  678|\n",
      "|                    dnq2|  663|\n",
      "|                    dpmu|  662|\n",
      "|                    9y6d|  658|\n",
      "|                    dr18|  657|\n",
      "|                    9v7c|  650|\n",
      "|                    cbj8|  639|\n",
      "|                    djgy|  637|\n",
      "|                    9yut|  633|\n",
      "|                    9vg6|  632|\n",
      "|                    dpxu|  627|\n",
      "|                    dn6q|  617|\n",
      "|                    c9k0|  614|\n",
      "|                    djn1|  612|\n",
      "+------------------------+-----+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.geohash != 's00000000000')\\\n",
    "    .groupBy(func.substring(df.geohash, 1, 4))\\\n",
    "    .agg(func.countDistinct('idfa').alias('count'))\\\n",
    "    .sort('count', ascending=False)\\\n",
    "    .show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of behaviour of IDFAs\n",
    "\n",
    "To get more insights into the behaviour of IDFAs, I would like to look at the following variables:\n",
    "- Top countries by volume\n",
    "- Top cities by volume\n",
    "- Distribution over platforms\n",
    "- Time of day activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+\n",
      "|country_code| count|\n",
      "+------------+------+\n",
      "|          US|189577|\n",
      "|          CA| 42627|\n",
      "|          GU|  4486|\n",
      "|          JP|   706|\n",
      "|          MX|   626|\n",
      "|          GB|   399|\n",
      "|          BR|   324|\n",
      "|          TR|   259|\n",
      "|          DE|   222|\n",
      "|          AU|   213|\n",
      "+------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as func\n",
    "from iso3166 import countries\n",
    "def toAlpha3(code):\n",
    "    return countries.get(code).alpha3\n",
    " \n",
    "udfToAlpha3=func.udf(toAlpha3)\n",
    "\n",
    "top_countries_df = df.groupBy(df.country_code)\\\n",
    "    .agg(func.countDistinct('idfa').alias('count'))\\\n",
    "    .orderBy(['count'], ascending=False)\n",
    "    \n",
    "top_countries_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for plotting, need to convert the country code to 3 letter code\n",
    "pandas_df =  top_countries_df.withColumn('alpha3',udfToAlpha3(df.country_code)).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~akaur3472/2.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.plotly as py\n",
    "import pandas as pd\n",
    "\n",
    "data = [ dict(\n",
    "        type = 'choropleth',\n",
    "        locations = pandas_df['alpha3'],\n",
    "        z = pandas_df['count'],\n",
    "        text = pandas_df['country_code'],\n",
    "        colorscale = [[0,\"rgb(5, 10, 172)\"],[0.35,\"rgb(40, 60, 190)\"],[0.5,\"rgb(70, 100, 245)\"],\\\n",
    "            [0.6,\"rgb(90, 120, 245)\"],[0.7,\"rgb(106, 137, 247)\"],[1,\"rgb(220, 220, 220)\"]],\n",
    "        autocolorscale = False,\n",
    "        reversescale = True,\n",
    "        marker = dict(\n",
    "            line = dict (\n",
    "                color = 'rgb(180,180,180)',\n",
    "                width = 0.5\n",
    "            ) ),\n",
    "        colorbar = dict(\n",
    "            autotick = True,\n",
    "            tickprefix = '',\n",
    "            title = 'Number of IDFAs'),\n",
    "      ) ]\n",
    "\n",
    "layout = dict(\n",
    "    title = 'Distribution of IDFAs over the world',\n",
    "    geo = dict(\n",
    "        showframe = False,\n",
    "        showcoastlines = False,\n",
    "        projection = dict(\n",
    "            type = 'Mercator'\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = dict( data=data, layout=layout )\n",
    "py.iplot( fig, validate=False, filename='world_map' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution by top cities\n",
    "Top cities by volume of IDFAs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|         city|count|\n",
      "+-------------+-----+\n",
      "|      Toronto| 6307|\n",
      "|    Barrigada| 4446|\n",
      "|      Houston| 3885|\n",
      "|     Columbus| 3018|\n",
      "|       Ottawa| 2635|\n",
      "|      Atlanta| 2604|\n",
      "|  Mississauga| 2439|\n",
      "|       Dallas| 2407|\n",
      "|      Calgary| 2352|\n",
      "|     Edmonton| 2021|\n",
      "|     Montréal| 1958|\n",
      "|     Richmond| 1908|\n",
      "|    Cleveland| 1858|\n",
      "|    Baltimore| 1847|\n",
      "|    Vancouver| 1662|\n",
      "| Indianapolis| 1564|\n",
      "|   Cincinnati| 1547|\n",
      "| Philadelphia| 1540|\n",
      "|     Hamilton| 1492|\n",
      "|    Knoxville| 1466|\n",
      "|  Saint Louis| 1456|\n",
      "|      Detroit| 1406|\n",
      "|    Charlotte| 1376|\n",
      "|     Columbia| 1362|\n",
      "|   Fort Worth| 1336|\n",
      "|   Birmingham| 1308|\n",
      "|      Chicago| 1255|\n",
      "|     Brampton| 1205|\n",
      "|    Nashville| 1201|\n",
      "|    Arlington| 1194|\n",
      "|     Winnipeg| 1185|\n",
      "| Jacksonville| 1168|\n",
      "|Oklahoma City| 1153|\n",
      "|      Raleigh| 1144|\n",
      "|   Burlington| 1110|\n",
      "|  Kansas City| 1106|\n",
      "|        Omaha| 1091|\n",
      "|  Minneapolis| 1056|\n",
      "|      Orlando| 1049|\n",
      "|      Vaughan| 1041|\n",
      "|  Springfield| 1030|\n",
      "|       London| 1009|\n",
      "|    Las Vegas|  992|\n",
      "|      Decatur|  969|\n",
      "|      Lincoln|  929|\n",
      "|      Madison|  902|\n",
      "|  San Antonio|  895|\n",
      "|      Phoenix|  879|\n",
      "|      Markham|  869|\n",
      "|   Washington|  858|\n",
      "+-------------+-----+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_cities_df = df.groupBy(df.city)\\\n",
    "    .agg(func.countDistinct('idfa').alias('count'))\\\n",
    "    .orderBy(['count'], ascending=False)\n",
    "    \n",
    "top_cities_df.show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the top 50 cities, most of these are big cities located in the US and Canada, which is expected. Barrigada is an exception as discussed earlier. Toronto has a higher chunk of traffic as compared to other cities, which points to the data being possibly collected for clients which are local. It is interesting that Houston has another bigger chunk of traffic, instead of a city with a bigger population, which again points to a big client/clients located in Houston."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution by platform\n",
    "Next, let's take a look at the top platforms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|platform| count|\n",
      "+--------+------+\n",
      "| android|204602|\n",
      "|     ios| 33609|\n",
      "+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "plat_df = df.groupBy(df.platform)\\\n",
    "    .agg(func.countDistinct('idfa').alias('count'))\\\n",
    "    .orderBy(['count'], ascending=False)\n",
    "    \n",
    "plat_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is interesting. I would have expected majority of the population to be from iOS since iPhones seem to be more popular in North America, but the volume for Android almost 9x that of iOS. It seems that more iOS users have opted out of interest based ads and turned off the tracking. Another possibility is that the apps from which this data comes are not as popular with iPhone users as opposed to Android phone users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Time of day analysis:\n",
    "\n",
    "We try to see whether there is a pattern in the time of day corresponding to the volume of the IDFAs overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "overall_tod = df.groupBy(func.hour(func.from_unixtime(df.event_time)).alias('utc_hour'))\\\n",
    "    .agg(func.countDistinct('idfa').alias('idfa_vol'))\\\n",
    "    .orderBy('utc_hour')\\\n",
    "    .toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~akaur3472/13.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.graph_objs as go\n",
    "data_overall = [go.Scatter(x=overall_tod['utc_hour'], y=overall_tod['idfa_vol'])]\n",
    "py.iplot(data_overall, filename='time_of_day_overall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~akaur3472/9.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "van_tod = df.filter(df.city == 'Vancouver')\\\n",
    "    .select(func.from_unixtime(df.event_time).alias('utc_time'), df.idfa)\\\n",
    "    .withColumn('pst_time', func.from_utc_timestamp('utc_time', 'PST'))\\\n",
    "    .groupBy(func.hour('utc_time').alias('utc_hour'), func.hour('pst_time').alias('pst_hour'))\\\n",
    "    .agg(func.countDistinct('idfa').alias('idfa_vol'))\\\n",
    "    .orderBy('utc_hour')\\\n",
    "    .toPandas()\n",
    "    \n",
    "\n",
    "data_van = [go.Scatter(x=van_tod['pst_hour'], y=van_tod['idfa_vol'])]\n",
    "py.iplot(data_van, filename='time_of_day_van')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~akaur3472/11.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tor_tod = df.filter(df.city == 'Toronto')\\\n",
    "    .select(func.from_unixtime(df.event_time).alias('utc_time'), df.idfa)\\\n",
    "    .withColumn('est_time', func.from_utc_timestamp('utc_time', 'EST'))\\\n",
    "    .groupBy(func.hour('utc_time').alias('utc_hour'), func.hour('est_time').alias('est_hour'))\\\n",
    "    .agg(func.countDistinct('idfa').alias('idfa_vol'))\\\n",
    "    .orderBy('utc_hour')\\\n",
    "    .toPandas()\n",
    "\n",
    "\n",
    "data_tor = [go.Scatter( x=tor_tod['est_hour'], y=tor_tod['idfa_vol'])]\n",
    "py.iplot(data_tor, filename='time_of_day_tor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
