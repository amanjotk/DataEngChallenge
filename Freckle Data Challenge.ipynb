{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the dataset\n",
    "\n",
    "An intial look at the raw unzipped data shows the files are in JSON format. Since JSON is a schema-based format and DataFrames are optimized to work efficiently with a data with a schema, I have used dataframes to analyze this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.2.0\n",
      "      /_/\n",
      "\n",
      "Using Python version 2.7.9 (default, Dec 15 2014 10:37:34)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "# initialize spark shell\n",
    "import os\n",
    "execfile(os.path.join(os.environ[\"SPARK_HOME\"], 'python/pyspark/shell.py'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- action: string (nullable = true)\n",
      " |-- api_key: string (nullable = true)\n",
      " |-- app_id: string (nullable = true)\n",
      " |-- beacon_major: long (nullable = true)\n",
      " |-- beacon_minor: long (nullable = true)\n",
      " |-- beacon_uuid: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- code: string (nullable = true)\n",
      " |-- community: string (nullable = true)\n",
      " |-- community_code: string (nullable = true)\n",
      " |-- country_code: string (nullable = true)\n",
      " |-- county: string (nullable = true)\n",
      " |-- county_code: string (nullable = true)\n",
      " |-- event_time: long (nullable = true)\n",
      " |-- geohash: string (nullable = true)\n",
      " |-- horizontal_accuracy: double (nullable = true)\n",
      " |-- idfa: string (nullable = true)\n",
      " |-- idfa_hash_alg: string (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- lng: double (nullable = true)\n",
      " |-- place: string (nullable = true)\n",
      " |-- platform: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- user_ip: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read in the data and print the schema\n",
    "\n",
    "df = spark.read.json('/Users/akaur/Desktop/DataEngChallenge/location-data-sample')\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics for location events per IDFA\n",
    "\n",
    "For the max, min, avg, std deviation of the number of location events per IDFA, first we get the count of the records per IDFA and store it in a new dataframe, then we get the values for the required metrics using the very handy 'describe' function from the spark inbuilt sql functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                idfa|count|\n",
      "+--------------------+-----+\n",
      "|b5b237fe-4ab2-4f0...|   28|\n",
      "|0894896b-1b58-4b8...|   58|\n",
      "|0446d012-6d80-4b2...|   36|\n",
      "|564fa141-580a-445...|   72|\n",
      "|4bf5568f-4369-421...|   31|\n",
      "|b2a03e10-3b45-479...|   94|\n",
      "|f4503b93-f2ec-418...|   48|\n",
      "|fe64cf85-bd56-4d1...|  245|\n",
      "|71f57c4d-78fa-448...|   33|\n",
      "|ef2d34f9-07fd-4cf...|   89|\n",
      "+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# number of locations events(records) per IDFA\n",
    "idfa_count = df.groupBy(df.idfa).count()\n",
    "idfa_count.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|             count|\n",
      "+-------+------------------+\n",
      "|  count|            238211|\n",
      "|   mean| 36.79234376246269|\n",
      "| stddev|118.69280626757613|\n",
      "|    min|                 1|\n",
      "|    max|             15999|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get the aggregation metrics for the count column\n",
    "idfa_count.describe('count').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the standard deviation being 118.7 and mean being 36.79, the IDFA with the max value(15999) definitely seems like an outlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geohashes of all coordinates\n",
    "In order to get the geohashes for all coordinates, we select distinct tuples of lat, long and geohash by first selecting the three columns and then doing a distinct over the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+------------+\n",
      "|       lat|        lng|     geohash|\n",
      "+----------+-----------+------------+\n",
      "|43.8799046|-79.7387178|dpz39s04cpnd|\n",
      "|43.0179897|-81.2123496|dpwhxznvzne0|\n",
      "| 45.268008| -75.306878|f243w2g1q83c|\n",
      "|39.8381067| -85.996203|dp4feh73z1r7|\n",
      "| 45.429277| -73.312884|f25f7wphtzp9|\n",
      "+----------+-----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# distinct (lat, lng, geohash) combinations\n",
    "geohash_df = df.select(df.lat, df.lng, df.geohash)\\\n",
    "    .distinct()\n",
    "    \n",
    "geohash_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the dataframe locally for later lookup if required\n",
    "geohash_df.write.parquet('/Users/akaur/PycharmProjects/DataEngChallenge-Amanjot/geohash_coordinates.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geohash - based clusters\n",
    "\n",
    "Using the information that locations/coordinates with similar geohash prefixes are close, I look at different length of geohash prefixes to see the volume of distinct IDFAs in the proximity and whether they can be classified as clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----+\n",
      "|     geohash| vol|\n",
      "+------------+----+\n",
      "|s00000000000|4427|\n",
      "|djfq0rzn7m70|  75|\n",
      "|dq21mmek4q6q|  73|\n",
      "|9vkh7wddguw5|  63|\n",
      "|dpz8336uu2eq|  61|\n",
      "|f244mdxpncbp|  58|\n",
      "|dpm5wpyg42f9|  52|\n",
      "|djfmbs7xs1j8|  48|\n",
      "|f241b833vv6j|  47|\n",
      "|djgzq3q23u2p|  46|\n",
      "|djkvw9r4j8vp|  45|\n",
      "|dn6m9tgey6mq|  44|\n",
      "|djt54wb39fhy|  44|\n",
      "|djdxvzvm9wvu|  43|\n",
      "|dnkkg7cw8k1b|  39|\n",
      "|dpherfur8ezf|  38|\n",
      "|dnq1zws4u9te|  38|\n",
      "|dpscv16bk3zf|  38|\n",
      "|c2b2mbftz52c|  37|\n",
      "|f2418x4h86s2|  37|\n",
      "+------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as func\n",
    "df.groupBy(df.geohash)\\\n",
    "    .agg(func.countDistinct(df.idfa).alias('vol'))\\\n",
    "    .sort('vol', ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that geohash 's00000000000' has a very high volume of IDFAs compared to any other geohash, this seems like an outlier caused by possibly artificial traffic or some other inaccuracy in the data. Let's check the cities/coordinates for this geohash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|     city|\n",
      "+---------+\n",
      "|Barrigada|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.city)\\\n",
    "    .filter(df.geohash == 's00000000000')\\\n",
    "    .distinct()\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the city Barrigada responsible for this unusually high amount of traffic is a small village with a population of  < 9K, it is safe to assume this is some kind of artificial/fraud/bot traffic. Going forward, we filter out this geohash in our analysis in order to avoid any skew in data because of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|geohash_4|count|\n",
      "+---------+-----+\n",
      "|     dpz8| 4315|\n",
      "|     dpz2| 3676|\n",
      "|     dpz9| 2535|\n",
      "|     f25d| 1938|\n",
      "|     c3nf| 1825|\n",
      "|     dpxr| 1792|\n",
      "|     f244| 1749|\n",
      "|     9vk1| 1743|\n",
      "|     9vg5| 1689|\n",
      "|     9vk0| 1636|\n",
      "|     dr4e| 1612|\n",
      "|     dn5b| 1595|\n",
      "|     c3x2| 1581|\n",
      "|     dpsc| 1574|\n",
      "|     9vg4| 1569|\n",
      "|     dqcx| 1569|\n",
      "|     dphg| 1558|\n",
      "|     dqcr| 1535|\n",
      "|     djgz| 1514|\n",
      "|     dnh0| 1510|\n",
      "|     9vk4| 1415|\n",
      "|     f25e| 1414|\n",
      "|     9vff| 1399|\n",
      "|     c2b2| 1384|\n",
      "|     dpsb| 1384|\n",
      "|     dpj5| 1356|\n",
      "|     djup| 1347|\n",
      "|     dpz3| 1321|\n",
      "|     c2b8| 1262|\n",
      "|     dr5r| 1262|\n",
      "|     f241| 1246|\n",
      "|     c28x| 1141|\n",
      "|     dn6m| 1116|\n",
      "|     dpzc| 1086|\n",
      "|     dngy| 1059|\n",
      "|     cbfg| 1053|\n",
      "|     9z7d| 1051|\n",
      "|     dq25|  991|\n",
      "|     dnh1|  982|\n",
      "|     9yzg|  981|\n",
      "|     dpxn|  980|\n",
      "|     dp3w|  972|\n",
      "|     9vfc|  971|\n",
      "|     dpmg|  971|\n",
      "|     dr72|  962|\n",
      "|     9yzu|  944|\n",
      "|     dngz|  936|\n",
      "|     9vgh|  934|\n",
      "|     9vg1|  925|\n",
      "|     dqcj|  924|\n",
      "|     dnkk|  918|\n",
      "|     djfq|  898|\n",
      "|     dnn3|  893|\n",
      "|     dqcm|  884|\n",
      "|     9qqj|  880|\n",
      "|     dn5c|  867|\n",
      "|     c3x0|  856|\n",
      "|     9q5c|  855|\n",
      "|     9vfg|  846|\n",
      "|     dp4d|  840|\n",
      "|     dq8v|  838|\n",
      "|     dp3t|  837|\n",
      "|     djun|  837|\n",
      "|     dnkh|  833|\n",
      "|     dp4f|  823|\n",
      "|     c3nc|  822|\n",
      "|     9qh0|  798|\n",
      "|     9y69|  795|\n",
      "|     dnq8|  794|\n",
      "|     dnru|  786|\n",
      "|     dq9c|  783|\n",
      "|     dpwz|  779|\n",
      "|     dn5r|  773|\n",
      "|     dpwh|  766|\n",
      "|     9zvx|  766|\n",
      "|     dphu|  762|\n",
      "|     dqcq|  759|\n",
      "|     dj3q|  750|\n",
      "|     dpxq|  728|\n",
      "|     dqch|  717|\n",
      "|     c28r|  705|\n",
      "|     dpqh|  699|\n",
      "|     9vrf|  697|\n",
      "|     9tbq|  696|\n",
      "|     djn4|  686|\n",
      "|     dpxj|  680|\n",
      "|     9vk2|  678|\n",
      "|     dnq2|  663|\n",
      "|     dpmu|  662|\n",
      "|     9y6d|  658|\n",
      "|     dr18|  657|\n",
      "|     9v7c|  650|\n",
      "|     cbj8|  639|\n",
      "|     djgy|  637|\n",
      "|     9yut|  633|\n",
      "|     9vg6|  632|\n",
      "|     dpxu|  627|\n",
      "|     dn6q|  617|\n",
      "|     c9k0|  614|\n",
      "|     dr5x|  612|\n",
      "+---------+-----+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "geohash_4 = df.filter(df.geohash != 's00000000000')\\\n",
    "    .groupBy(func.substring(df.geohash, 1, 4).alias('geohash_4'))\\\n",
    "    .agg(func.countDistinct('idfa').alias('count'))\\\n",
    "    .sort('count', ascending=False)\n",
    "    \n",
    "    \n",
    "geohash_4.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save these cluster volumes to a local parquet file\n",
    "geohash_4.write.parquet('/Users/akaur/PycharmProjects/DataEngChallenge-Amanjot/geohash4_distribution.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|         city|count|\n",
      "+-------------+-----+\n",
      "|      Toronto| 6307|\n",
      "|    Barrigada| 4446|\n",
      "|      Houston| 3885|\n",
      "|     Columbus| 3018|\n",
      "|       Ottawa| 2635|\n",
      "|      Atlanta| 2604|\n",
      "|  Mississauga| 2439|\n",
      "|       Dallas| 2407|\n",
      "|      Calgary| 2352|\n",
      "|     Edmonton| 2021|\n",
      "|     Montréal| 1958|\n",
      "|     Richmond| 1908|\n",
      "|    Cleveland| 1858|\n",
      "|    Baltimore| 1847|\n",
      "|    Vancouver| 1662|\n",
      "| Indianapolis| 1564|\n",
      "|   Cincinnati| 1547|\n",
      "| Philadelphia| 1540|\n",
      "|     Hamilton| 1492|\n",
      "|    Knoxville| 1466|\n",
      "|  Saint Louis| 1456|\n",
      "|      Detroit| 1406|\n",
      "|    Charlotte| 1376|\n",
      "|     Columbia| 1362|\n",
      "|   Fort Worth| 1336|\n",
      "|   Birmingham| 1308|\n",
      "|      Chicago| 1255|\n",
      "|     Brampton| 1205|\n",
      "|    Nashville| 1201|\n",
      "|    Arlington| 1194|\n",
      "|     Winnipeg| 1185|\n",
      "| Jacksonville| 1168|\n",
      "|Oklahoma City| 1153|\n",
      "|      Raleigh| 1144|\n",
      "|   Burlington| 1110|\n",
      "|  Kansas City| 1106|\n",
      "|        Omaha| 1091|\n",
      "|  Minneapolis| 1056|\n",
      "|      Orlando| 1049|\n",
      "|      Vaughan| 1041|\n",
      "|  Springfield| 1030|\n",
      "|       London| 1009|\n",
      "|    Las Vegas|  992|\n",
      "|      Decatur|  969|\n",
      "|      Lincoln|  929|\n",
      "|      Madison|  902|\n",
      "|  San Antonio|  895|\n",
      "|      Phoenix|  879|\n",
      "|      Markham|  869|\n",
      "|   Washington|  858|\n",
      "|      Buffalo|  855|\n",
      "|Richmond Hill|  848|\n",
      "|       Aurora|  833|\n",
      "|      Windsor|  829|\n",
      "|   Greenville|  825|\n",
      "|       Austin|  808|\n",
      "| Fayetteville|  782|\n",
      "|       Surrey|  775|\n",
      "|       Tucson|  770|\n",
      "|      Burnaby|  760|\n",
      "|   Saint Paul|  759|\n",
      "|     Oakville|  755|\n",
      "|   Wilmington|  752|\n",
      "|       Dayton|  747|\n",
      "|      Jackson|  743|\n",
      "|       Mobile|  743|\n",
      "|      Memphis|  741|\n",
      "|       Milton|  728|\n",
      "|   Louisville|  724|\n",
      "|       Durham|  722|\n",
      "|     Marietta|  721|\n",
      "|       Denver|  715|\n",
      "|  Los Angeles|  707|\n",
      "|    Lancaster|  695|\n",
      "|  Chattanooga|  690|\n",
      "|       Newark|  673|\n",
      "|        Laval|  655|\n",
      "|     Brooklyn|  655|\n",
      "|        Plano|  654|\n",
      "|        Tampa|  647|\n",
      "|    Lexington|  640|\n",
      "|    Saskatoon|  640|\n",
      "|   Huntsville|  634|\n",
      "|       Canton|  632|\n",
      "|   Montgomery|  628|\n",
      "|        Miami|  626|\n",
      "|  Baton Rouge|  591|\n",
      "|    Kitchener|  583|\n",
      "|    Cambridge|  572|\n",
      "|  Gainesville|  569|\n",
      "|  Little Rock|  567|\n",
      "|   Charleston|  565|\n",
      "|     Kingston|  564|\n",
      "|     Franklin|  562|\n",
      "|       Spring|  559|\n",
      "|       Fresno|  548|\n",
      "|     San Jose|  547|\n",
      "|     Waterloo|  546|\n",
      "|     New York|  544|\n",
      "|     Portland|  541|\n",
      "+-------------+-----+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(df.city)\\\n",
    "    .agg(func.countDistinct('idfa').alias('count'))\\\n",
    "    .orderBy(['count'], ascending=False)\\\n",
    "    .show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at the IDFA volumes for different lengths of geohash prefixes, we see that the volume distribution over geohashes if we consider first 4 letters is similar to what we see for volume distribution for different cities. Thus we can consider these as clusters. The number of people in the clusters is upto 4K people, and based on the Wikipedia page for geohashes, km error at this level of precision is +/- 20 kms, which is close to the usual size of a metropolitan area.\n",
    "\n",
    "Let's see if we can find more granular clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|geohash_4|count|\n",
      "+---------+-----+\n",
      "|    dpz83| 1921|\n",
      "|    dpz82|  879|\n",
      "|    f244m|  730|\n",
      "|    c2b2q|  716|\n",
      "|    f25dv|  695|\n",
      "|    dpz8b|  673|\n",
      "|    dpz8f|  660|\n",
      "|    dpz89|  642|\n",
      "|    dpz86|  637|\n",
      "|    dpz8d|  606|\n",
      "|    dqcx8|  579|\n",
      "|    dpz8c|  577|\n",
      "|    dpz2j|  561|\n",
      "|    dpz94|  558|\n",
      "|    dpz88|  553|\n",
      "|    dpz2r|  497|\n",
      "|    dpz2n|  497|\n",
      "|    dpxrg|  472|\n",
      "|    dpz2w|  471|\n",
      "|    c3nfk|  466|\n",
      "|    dpz2x|  465|\n",
      "|    dpz25|  444|\n",
      "|    f244h|  442|\n",
      "|    dpz80|  441|\n",
      "|    c2b80|  431|\n",
      "|    f25dt|  420|\n",
      "|    dpz95|  420|\n",
      "|    dpz90|  411|\n",
      "|    dpz9h|  410|\n",
      "|    f25dy|  409|\n",
      "|    dpxru|  408|\n",
      "|    dpz2m|  405|\n",
      "|    dpz96|  403|\n",
      "|    dpz2t|  401|\n",
      "|    dpz2p|  397|\n",
      "|    c3x29|  396|\n",
      "|    dpz8g|  396|\n",
      "|    dpz2z|  395|\n",
      "|    dn5bp|  394|\n",
      "|    dpz93|  394|\n",
      "|    f25ds|  385|\n",
      "|    c28ry|  377|\n",
      "|    dpxrd|  377|\n",
      "|    c2b2n|  374|\n",
      "|    c3nfh|  372|\n",
      "|    f25du|  371|\n",
      "|    f244q|  366|\n",
      "|    dpxre|  365|\n",
      "|    dpz8e|  361|\n",
      "|    dqcrx|  361|\n",
      "|    c3nf7|  359|\n",
      "|    dqcx9|  358|\n",
      "|    djgzq|  353|\n",
      "|    c2b81|  346|\n",
      "|    dpxrf|  344|\n",
      "|    c2b2p|  344|\n",
      "|    dpxnx|  341|\n",
      "|    c2b2m|  340|\n",
      "|    c3x21|  336|\n",
      "|    dphgr|  333|\n",
      "|    cbfgv|  332|\n",
      "|    f25eh|  332|\n",
      "|    f25dg|  322|\n",
      "|    c3x23|  322|\n",
      "|    dpz29|  321|\n",
      "|    f241g|  319|\n",
      "|    dpz3n|  316|\n",
      "|    dpxq8|  314|\n",
      "|    c2b85|  313|\n",
      "|    dpz99|  313|\n",
      "|    dpz24|  312|\n",
      "|    dpz3j|  305|\n",
      "|    dr4e3|  305|\n",
      "|    dpz2y|  303|\n",
      "|    f2445|  303|\n",
      "|    dpz92|  303|\n",
      "|    dn6m9|  302|\n",
      "|    dpxr4|  300|\n",
      "|    dpz2k|  299|\n",
      "|    dpz2s|  299|\n",
      "|    dpxr6|  296|\n",
      "|    9vg4t|  295|\n",
      "|    dpxjy|  288|\n",
      "|    dpxrc|  286|\n",
      "|    cbfgu|  285|\n",
      "|    c2b82|  285|\n",
      "|    dpz28|  284|\n",
      "|    dr5ru|  283|\n",
      "|    dpz2q|  282|\n",
      "|    9vg4m|  280|\n",
      "|    f244k|  280|\n",
      "|    9qqj7|  279|\n",
      "|    f25d8|  274|\n",
      "|    c3x28|  273|\n",
      "|    dpz9j|  273|\n",
      "|    dpz3p|  273|\n",
      "|    dpz2h|  273|\n",
      "|    dpz3m|  271|\n",
      "|    dpzc2|  271|\n",
      "|    dpz98|  270|\n",
      "+---------+-----+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "geohash_5 = df.filter(df.geohash != 's00000000000')\\\n",
    "    .groupBy(func.substring(df.geohash, 1, 5).alias('geohash_4'))\\\n",
    "    .agg(func.countDistinct('idfa').alias('count'))\\\n",
    "    .sort('count', ascending=False)\n",
    "    \n",
    "geohash_5.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save to local \n",
    "geohash_5.write.parquet('/Users/akaur/PycharmProjects/DataEngChallenge-Amanjot/geohash5_distribution.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this level of precision, the km error is +/- 2.4 kms which can be defined as a community/neighbourhood. These can also be considered as valid clusters, which number of people averaging ~400."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of behaviour of IDFAs\n",
    "\n",
    "To get more insights into the behaviour of IDFAs, I would like to look at the following variables:\n",
    "- Top countries by volume\n",
    "- Top cities by volume\n",
    "- Distribution over platforms\n",
    "- Time of day activity\n",
    "- IDFAs linked with multiple locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+\n",
      "|country_code| count|\n",
      "+------------+------+\n",
      "|          US|189577|\n",
      "|          CA| 42627|\n",
      "|          GU|  4486|\n",
      "|          JP|   706|\n",
      "|          MX|   626|\n",
      "|          GB|   399|\n",
      "|          BR|   324|\n",
      "|          TR|   259|\n",
      "|          DE|   222|\n",
      "|          AU|   213|\n",
      "+------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as func\n",
    "from iso3166 import countries\n",
    "def toAlpha3(code):\n",
    "    return countries.get(code).alpha3\n",
    " \n",
    "udfToAlpha3=func.udf(toAlpha3)\n",
    "\n",
    "countries_df = df.groupBy(df.country_code)\\\n",
    "    .agg(func.countDistinct('idfa').alias('count'))\\\n",
    "    .orderBy(['count'], ascending=False)\n",
    "    \n",
    "# show top 10\n",
    "countries_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the distribution to local\n",
    "countries_df.write.parquet('/Users/akaur/PycharmProjects/DataEngChallenge-Amanjot/countries_distribution.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for plotting, need to convert the country code to 3 letter code\n",
    "pandas_countries =  countries_df.withColumn('alpha3',udfToAlpha3(df.country_code))\\\n",
    "    .toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~akaur3472/2.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the following code is taken from plotly examples and modified to represent this data\n",
    "\n",
    "import plotly.plotly as py\n",
    "import pandas as pd\n",
    "\n",
    "data = [ dict(\n",
    "        type = 'choropleth',\n",
    "        locations = pandas_countries['alpha3'],\n",
    "        z = pandas_countries['count'],\n",
    "        text = pandas_countries['country_code'],\n",
    "        colorscale = [[0,\"rgb(5, 10, 172)\"],[0.35,\"rgb(40, 60, 190)\"],[0.5,\"rgb(70, 100, 245)\"],\\\n",
    "            [0.6,\"rgb(90, 120, 245)\"],[0.7,\"rgb(106, 137, 247)\"],[1,\"rgb(220, 220, 220)\"]],\n",
    "        autocolorscale = False,\n",
    "        reversescale = True,\n",
    "        marker = dict(\n",
    "            line = dict (\n",
    "                color = 'rgb(180,180,180)',\n",
    "                width = 0.5\n",
    "            ) ),\n",
    "        colorbar = dict(\n",
    "            autotick = True,\n",
    "            tickprefix = '',\n",
    "            title = 'Number of IDFAs'),\n",
    "      ) ]\n",
    "\n",
    "layout = dict(\n",
    "    title = 'Distribution of IDFAs over the world',\n",
    "    geo = dict(\n",
    "        showframe = False,\n",
    "        showcoastlines = False,\n",
    "        projection = dict(\n",
    "            type = 'Mercator'\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = dict( data=data, layout=layout )\n",
    "py.iplot( fig, validate=False, filename='world_map' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution by top cities\n",
    "Top cities by volume of IDFAs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|         city|count|\n",
      "+-------------+-----+\n",
      "|      Toronto| 6307|\n",
      "|    Barrigada| 4446|\n",
      "|      Houston| 3885|\n",
      "|     Columbus| 3018|\n",
      "|       Ottawa| 2635|\n",
      "|      Atlanta| 2604|\n",
      "|  Mississauga| 2439|\n",
      "|       Dallas| 2407|\n",
      "|      Calgary| 2352|\n",
      "|     Edmonton| 2021|\n",
      "|     Montréal| 1958|\n",
      "|     Richmond| 1908|\n",
      "|    Cleveland| 1858|\n",
      "|    Baltimore| 1847|\n",
      "|    Vancouver| 1662|\n",
      "| Indianapolis| 1564|\n",
      "|   Cincinnati| 1547|\n",
      "| Philadelphia| 1540|\n",
      "|     Hamilton| 1492|\n",
      "|    Knoxville| 1466|\n",
      "|  Saint Louis| 1456|\n",
      "|      Detroit| 1406|\n",
      "|    Charlotte| 1376|\n",
      "|     Columbia| 1362|\n",
      "|   Fort Worth| 1336|\n",
      "|   Birmingham| 1308|\n",
      "|      Chicago| 1255|\n",
      "|     Brampton| 1205|\n",
      "|    Nashville| 1201|\n",
      "|    Arlington| 1194|\n",
      "|     Winnipeg| 1185|\n",
      "| Jacksonville| 1168|\n",
      "|Oklahoma City| 1153|\n",
      "|      Raleigh| 1144|\n",
      "|   Burlington| 1110|\n",
      "|  Kansas City| 1106|\n",
      "|        Omaha| 1091|\n",
      "|  Minneapolis| 1056|\n",
      "|      Orlando| 1049|\n",
      "|      Vaughan| 1041|\n",
      "|  Springfield| 1030|\n",
      "|       London| 1009|\n",
      "|    Las Vegas|  992|\n",
      "|      Decatur|  969|\n",
      "|      Lincoln|  929|\n",
      "|      Madison|  902|\n",
      "|  San Antonio|  895|\n",
      "|      Phoenix|  879|\n",
      "|      Markham|  869|\n",
      "|   Washington|  858|\n",
      "+-------------+-----+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cities_df = df.groupBy(df.city)\\\n",
    "    .agg(func.countDistinct('idfa').alias('count'))\\\n",
    "    .orderBy(['count'], ascending=False)\n",
    "    \n",
    "# get top 50    \n",
    "cities_df.show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the distribution to local\n",
    "cities_df.write.parquet('/Users/akaur/PycharmProjects/DataEngChallenge-Amanjot/ct_distribution.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the top 50 cities, most of these are big cities located in the US and Canada, which is expected. Barrigada is an exception as discussed earlier. Toronto has a higher chunk of traffic as compared to other cities, followed by Houston. This points to the data being possibly collected for clients which are local, or from apps that are more popular in these areas. It is interesting that Houston has the second biggest chunk of traffic, instead of a city with a bigger population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution by platform\n",
    "Next, let's take a look at the top platforms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|platform| count|\n",
      "+--------+------+\n",
      "| android|204602|\n",
      "|     ios| 33609|\n",
      "+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "plat_df = df.groupBy(df.platform)\\\n",
    "    .agg(func.countDistinct('idfa').alias('count'))\\\n",
    "    .orderBy(['count'], ascending=False)\n",
    "    \n",
    "plat_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is interesting. I would have expected majority of the population to be from iOS since iPhones seem to be more popular in North America, but the volume for Android almost 9x that of iOS. It seems that more iOS users have opted out of interest based ads and turned off the tracking. Another possibility is that the apps from which this data comes are not as popular with iPhone users as opposed to Android phone users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Time of day analysis:\n",
    "\n",
    "We try to see whether there is a pattern in the time of day corresponding to the volume of the IDFAs overall. Before that, we check to see what is the time range for the sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+\n",
      "|      min(utc_time)|      max(utc_time)|\n",
      "+-------------------+-------------------+\n",
      "|2017-03-31 19:57:38|2017-04-01 20:01:36|\n",
      "+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(func.from_unixtime(df.event_time).alias('utc_time'))\\\n",
    "    .agg(func.min('utc_time'), func.max('utc_time'))\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the data is for 24 hours, not sure if we can conclude much about time of day activity from just one day of data, but let's try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "overall_tod = df.groupBy(func.hour(func.from_unixtime(df.event_time)).alias('utc_hour'))\\\n",
    "    .agg(func.countDistinct('idfa').alias('idfa_vol'))\\\n",
    "    .orderBy('utc_hour')\\\n",
    "    .toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~akaur3472/13.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.graph_objs as go\n",
    "data_overall = [go.Scatter(x=overall_tod['utc_hour'], y=overall_tod['idfa_vol'])]\n",
    "layout = dict(title = 'Distribution of IDFAs over the day',\n",
    "              xaxis = dict(title = 'UTC hour'),\n",
    "              yaxis = dict(title = 'Volume of IDFAs'),\n",
    "              )\n",
    "fig = dict(data=data_overall, layout=layout)\n",
    "py.iplot(fig, filename='time_of_day_overall')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above line chart shows that the peak of activity happens during 11 AM UTC to 8 PM UTC which is 6 AM EST to 3 PM EST and 3 AM PST to 12 noon PST. This doesn't seem to make much intuitive sense but it might be because of the IDFAs being distributed over multiple timezones. Let's take a closer look at two cities with higher volumes, one in the EST timezone (Toronto) and one in the PST timezone (Vancouver)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~akaur3472/9.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "van_tod = df.filter(df.city == 'Vancouver')\\\n",
    "    .select(func.from_unixtime(df.event_time).alias('utc_time'), df.idfa)\\\n",
    "    .withColumn('pst_time', func.from_utc_timestamp('utc_time', 'PST'))\\\n",
    "    .groupBy(func.hour('utc_time').alias('utc_hour'), func.hour('pst_time').alias('pst_hour'))\\\n",
    "    .agg(func.countDistinct('idfa').alias('idfa_vol'))\\\n",
    "    .orderBy('pst_hour')\\\n",
    "    .toPandas()\n",
    "    \n",
    "\n",
    "data_van = [go.Scatter(x=van_tod['pst_hour'], y=van_tod['idfa_vol'])]\n",
    "layout = dict(title = 'Distribution of IDFAs over the day',\n",
    "              xaxis = dict(title = 'PST hour'),\n",
    "              yaxis = dict(title = 'Volume of IDFAs'),\n",
    "              )\n",
    "fig = dict(data=data_van, layout=layout)\n",
    "py.iplot(fig, filename='time_of_day_van')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~akaur3472/11.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tor_tod = df.filter(df.city == 'Toronto')\\\n",
    "    .select(func.from_unixtime(df.event_time).alias('utc_time'), df.idfa)\\\n",
    "    .withColumn('est_time', func.from_utc_timestamp('utc_time', 'EST'))\\\n",
    "    .groupBy(func.hour('utc_time').alias('utc_hour'), func.hour('est_time').alias('est_hour'))\\\n",
    "    .agg(func.countDistinct('idfa').alias('idfa_vol'))\\\n",
    "    .orderBy('est_hour')\\\n",
    "    .toPandas()\n",
    "\n",
    "\n",
    "data_tor = [go.Scatter( x=tor_tod['est_hour'], y=tor_tod['idfa_vol'])]\n",
    "py.iplot(data_tor, filename='time_of_day_tor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the two line graphs above, we see more of a trend for individual cities with peak of traffic being between 5 AM - 3 PM. This makes a little more intuitive sense, since this coincides more closely with a workday. That being said, since the data ranges over just one day, it is not a large enough sample size to conclude for trends over time of day for a usual day of week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locations associated with a single IDFA\n",
    "\n",
    "Let's see if there are any users which are associated with multiple cities during this sample time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|                idfa|num_cities|\n",
      "+--------------------+----------+\n",
      "|00000000-0000-000...|      2079|\n",
      "|74eac213-504f-43d...|        93|\n",
      "|da0e90fb-19e0-487...|        91|\n",
      "|f979ed6f-0461-46c...|        83|\n",
      "|653b5c7a-64d2-4b7...|        76|\n",
      "|907e2e13-17ad-4c0...|        73|\n",
      "|843600f6-5878-4b7...|        70|\n",
      "|1ffedf96-efaf-408...|        69|\n",
      "|9fcb9870-29c2-4c4...|        63|\n",
      "|3c22ff88-e193-4bf...|        62|\n",
      "|1da43983-c834-4fb...|        61|\n",
      "|1e588609-11f0-48b...|        61|\n",
      "|362eb796-25b8-483...|        61|\n",
      "|7bacefce-e646-483...|        60|\n",
      "|fd33ab05-f744-4b1...|        60|\n",
      "|a663f67e-35b3-4aa...|        60|\n",
      "|a19d0dca-af40-4c9...|        60|\n",
      "|6b150901-7aeb-46c...|        59|\n",
      "|45606497-5fab-484...|        58|\n",
      "|3d12507f-cbe2-487...|        58|\n",
      "+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loc_df = df.groupBy(df.idfa)\\\n",
    "    .agg(func.countDistinct('city').alias('num_cities'))\\\n",
    "    .orderBy(['num_cities'], ascending=False)\n",
    "       \n",
    "loc_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems weird that there are users who are associated with >40 cities in a single day. This might point to something off with the 'geohash' collection parameter. Let's take a look at the stats for the num_cities parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|        num_cities|\n",
      "+-------+------------------+\n",
      "|  count|            238211|\n",
      "|   mean| 2.145371120561183|\n",
      "| stddev|4.9325567454032475|\n",
      "|    min|                 1|\n",
      "|    max|              2079|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loc_df.describe('num_cities').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is interesting that the mean for this number of cities associated with an IDFA is > 2. This might be skewed by noisy/test users e.g. the one with IDFA starting with '00000000-0000-000...' which has as many as 2079 cities associated with it. Let's take a look at the distribution of number of cities versus number of IDFAs linked to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+\n",
      "|num_cities|num_idfa|\n",
      "+----------+--------+\n",
      "|         1|  136919|\n",
      "|         2|   45238|\n",
      "|         3|   22724|\n",
      "|         4|   12534|\n",
      "|         5|    7301|\n",
      "|         6|    4201|\n",
      "|         7|    2667|\n",
      "|         8|    1700|\n",
      "|         9|    1144|\n",
      "|        10|     856|\n",
      "|        11|     533|\n",
      "|        12|     467|\n",
      "|        13|     296|\n",
      "|        14|     277|\n",
      "|        15|     186|\n",
      "|        16|     185|\n",
      "|        17|     122|\n",
      "|        18|     115|\n",
      "|        20|      89|\n",
      "|        19|      84|\n",
      "|        21|      59|\n",
      "|        23|      46|\n",
      "|        22|      42|\n",
      "|        24|      33|\n",
      "|        26|      31|\n",
      "|        25|      29|\n",
      "|        28|      28|\n",
      "|        27|      28|\n",
      "|        29|      24|\n",
      "|        30|      22|\n",
      "|        31|      20|\n",
      "|        35|      19|\n",
      "|        32|      18|\n",
      "|        37|      16|\n",
      "|        36|      12|\n",
      "|        33|      12|\n",
      "|        34|      12|\n",
      "|        41|      10|\n",
      "|        39|      10|\n",
      "|        42|       9|\n",
      "|        40|       9|\n",
      "|        38|       8|\n",
      "|        47|       8|\n",
      "|        44|       7|\n",
      "|        46|       7|\n",
      "|        48|       5|\n",
      "|        45|       5|\n",
      "|        60|       4|\n",
      "|        51|       4|\n",
      "|        52|       3|\n",
      "|        43|       3|\n",
      "|        55|       3|\n",
      "|        61|       3|\n",
      "|        56|       3|\n",
      "|        58|       3|\n",
      "|        49|       2|\n",
      "|        54|       2|\n",
      "|        57|       2|\n",
      "|      2079|       1|\n",
      "|        93|       1|\n",
      "|        76|       1|\n",
      "|        91|       1|\n",
      "|        83|       1|\n",
      "|        63|       1|\n",
      "|        73|       1|\n",
      "|        69|       1|\n",
      "|        70|       1|\n",
      "|        62|       1|\n",
      "|        59|       1|\n",
      "|        50|       1|\n",
      "+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loc_df.groupBy(loc_df.num_cities)\\\n",
    "    .agg(func.countDistinct('idfa').alias('num_idfa'))\\\n",
    "    .orderBy(['num_idfa'], ascending=False)\\\n",
    "    .show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems much more intuitive: A high volume of the IDFAs have a single city associated with them, and most of them have <= 4 cities associated with them. The IDFAs with > 20 cities associated with them are lesser in number and can be considered noise, but it is still weird that there are any IDFAs which show up in upto 20 cities."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
